{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/diabetes_prediction_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>smoking_history</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>never</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>current</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Female</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Female</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>19.31</td>\n",
       "      <td>6.5</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>23.86</td>\n",
       "      <td>5.7</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Male</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>33.64</td>\n",
       "      <td>4.8</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Female</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age  hypertension  heart_disease smoking_history    bmi  \\\n",
       "0  Female  80.0             0              1           never  25.19   \n",
       "1  Female  54.0             0              0         No Info  27.32   \n",
       "2    Male  28.0             0              0           never  27.32   \n",
       "3  Female  36.0             0              0         current  23.45   \n",
       "4    Male  76.0             1              1         current  20.14   \n",
       "5  Female  20.0             0              0           never  27.32   \n",
       "6  Female  44.0             0              0           never  19.31   \n",
       "7  Female  79.0             0              0         No Info  23.86   \n",
       "8    Male  42.0             0              0           never  33.64   \n",
       "9  Female  32.0             0              0           never  27.32   \n",
       "\n",
       "   HbA1c_level  blood_glucose_level  diabetes  \n",
       "0          6.6                  140         0  \n",
       "1          6.6                   80         0  \n",
       "2          5.7                  158         0  \n",
       "3          5.0                  155         0  \n",
       "4          4.8                  155         0  \n",
       "5          6.6                   85         0  \n",
       "6          6.5                  200         1  \n",
       "7          5.7                   85         0  \n",
       "8          4.8                  145         0  \n",
       "9          5.0                  100         0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                  object\n",
       "age                    float64\n",
       "hypertension             int64\n",
       "heart_disease            int64\n",
       "smoking_history         object\n",
       "bmi                    float64\n",
       "HbA1c_level            float64\n",
       "blood_glucose_level      int64\n",
       "diabetes                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot Encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoded = pd.get_dummies(data, columns=['gender', 'smoking_history'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>gender_Other</th>\n",
       "      <th>smoking_history_current</th>\n",
       "      <th>smoking_history_ever</th>\n",
       "      <th>smoking_history_former</th>\n",
       "      <th>smoking_history_never</th>\n",
       "      <th>smoking_history_not current</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.31</td>\n",
       "      <td>6.5</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>79.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.86</td>\n",
       "      <td>5.7</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.64</td>\n",
       "      <td>4.8</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  hypertension  heart_disease    bmi  HbA1c_level  blood_glucose_level  \\\n",
       "0  80.0             0              1  25.19          6.6                  140   \n",
       "1  54.0             0              0  27.32          6.6                   80   \n",
       "2  28.0             0              0  27.32          5.7                  158   \n",
       "3  36.0             0              0  23.45          5.0                  155   \n",
       "4  76.0             1              1  20.14          4.8                  155   \n",
       "5  20.0             0              0  27.32          6.6                   85   \n",
       "6  44.0             0              0  19.31          6.5                  200   \n",
       "7  79.0             0              0  23.86          5.7                   85   \n",
       "8  42.0             0              0  33.64          4.8                  145   \n",
       "9  32.0             0              0  27.32          5.0                  100   \n",
       "\n",
       "   diabetes  gender_Male  gender_Other  smoking_history_current  \\\n",
       "0         0        False         False                    False   \n",
       "1         0        False         False                    False   \n",
       "2         0         True         False                    False   \n",
       "3         0        False         False                     True   \n",
       "4         0         True         False                     True   \n",
       "5         0        False         False                    False   \n",
       "6         1        False         False                    False   \n",
       "7         0        False         False                    False   \n",
       "8         0         True         False                    False   \n",
       "9         0        False         False                    False   \n",
       "\n",
       "   smoking_history_ever  smoking_history_former  smoking_history_never  \\\n",
       "0                 False                   False                   True   \n",
       "1                 False                   False                  False   \n",
       "2                 False                   False                   True   \n",
       "3                 False                   False                  False   \n",
       "4                 False                   False                  False   \n",
       "5                 False                   False                   True   \n",
       "6                 False                   False                   True   \n",
       "7                 False                   False                  False   \n",
       "8                 False                   False                   True   \n",
       "9                 False                   False                   True   \n",
       "\n",
       "   smoking_history_not current  \n",
       "0                        False  \n",
       "1                        False  \n",
       "2                        False  \n",
       "3                        False  \n",
       "4                        False  \n",
       "5                        False  \n",
       "6                        False  \n",
       "7                        False  \n",
       "8                        False  \n",
       "9                        False  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_encoded.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_encoded.drop('diabetes', axis=1)\n",
    "y = data_encoded['diabetes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/02 11:36:50 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2024/09/02 11:36:50 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step\n",
      "INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
      "INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
      "INFO  [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
      "INFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
      "INFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
      "INFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
      "INFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
      "INFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
      "INFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
      "INFO  [alembic.runtime.migration] Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
      "INFO  [alembic.runtime.migration] Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
      "INFO  [alembic.runtime.migration] Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
      "INFO  [alembic.runtime.migration] Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
      "INFO  [alembic.runtime.migration] Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
      "INFO  [alembic.runtime.migration] Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "2024/09/02 11:36:50 INFO mlflow.tracking.fluent: Experiment with name 'demo-experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/Users/bwhom/Desktop/Labs/labs/mlruns/1', creation_time=1725302210897, experiment_id='1', last_update_time=1725302210897, lifecycle_stage='active', name='demo-experiment', tags={}>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri('sqlite:///mlflow.db')\n",
    "mlflow.set_experiment('demo-experiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_file = \"saved_data/X_train.csv\"\n",
    "X_test_file = \"saved_data/X_test.csv\"\n",
    "y_train_file = \"saved_data/y_train.csv\"\n",
    "y_test_file = \"saved_data/y_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train).to_csv(X_train_file, index=False)\n",
    "pd.DataFrame(X_test).to_csv(X_test_file, index=False)\n",
    "pd.DataFrame(y_train).to_csv(y_train_file, index=False)\n",
    "pd.DataFrame(y_test).to_csv(y_test_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "\n",
    "    mlflow.log_artifact(X_train_file)\n",
    "    mlflow.log_artifact(X_test_file)\n",
    "    mlflow.log_artifact(y_train_file)\n",
    "    mlflow.log_artifact(y_test_file)\n",
    "\n",
    "    mlflow.set_tags({\"Model\":\"Logistic Regression\", \"Train Data\": \"All Features\"})\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000, random_state=39)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric('precision', precision)\n",
    "    mlflow.log_metric('recall', recall)\n",
    "mlflow.end_run()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = [None, 10, 20, 30]\n",
    "min_samples_splits = [2, 5, 10]\n",
    "min_samples_leaves = [1, 2, 4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for max_depth in max_depths:\n",
    "    for min_samples_split in min_samples_splits:\n",
    "        for min_samples_leaf in min_samples_leaves:\n",
    "            with mlflow.start_run():\n",
    "\n",
    "                mlflow.set_tags({\"Model\":\"Decision Tree\", \"Train Data\": \"All Features\"})\n",
    "\n",
    "                dt = DecisionTreeClassifier(max_depth=max_depth,\n",
    "                                            min_samples_split=min_samples_split,\n",
    "                                            min_samples_leaf=min_samples_leaf,\n",
    "                                            random_state=39)\n",
    "\n",
    "                dt.fit(X_train, y_train)\n",
    "\n",
    "                y_pred = dt.predict(X_test)\n",
    "\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision = precision_score(y_test, y_pred)\n",
    "                recall = recall_score(y_test, y_pred)\n",
    "\n",
    "                mlflow.log_params({\n",
    "                    'max_depth': max_depth,\n",
    "                    'min_samples_split': min_samples_split,\n",
    "                    'min_samples_leaf': min_samples_leaf\n",
    "                })\n",
    "\n",
    "                mlflow.log_metric(\"accuracy\", accuracy)\n",
    "                mlflow.log_metric('precision', precision)\n",
    "                mlflow.log_metric('recall', recall)\n",
    "\n",
    "                mlflow.log_artifact(X_train_file)\n",
    "                mlflow.log_artifact(X_test_file)\n",
    "                mlflow.log_artifact(y_train_file)\n",
    "                mlflow.log_artifact(y_test_file)\n",
    "\n",
    "        mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_estimators = [50, 100, 150]\n",
    "max_depths = [10, 20]\n",
    "min_samples_splits = [2, 5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_estimator in n_estimators:\n",
    "    for max_depth in max_depths:\n",
    "        for min_samples_split in min_samples_splits:\n",
    "            with mlflow.start_run():\n",
    "\n",
    "                mlflow.set_tags({\"Model\":\"Random Forest\", \"Train Data\": \"All Features\"})\n",
    "\n",
    "                rf = RandomForestClassifier(n_estimators=n_estimator,\n",
    "                                            max_depth=max_depth,\n",
    "                                            min_samples_split=min_samples_split,\n",
    "                                            random_state=39)\n",
    "                rf.fit(X_train, y_train)\n",
    "\n",
    "                y_pred = rf.predict(X_test)\n",
    "\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision = precision_score(y_test, y_pred)\n",
    "                recall = recall_score(y_test, y_pred)\n",
    "\n",
    "                mlflow.log_params({\n",
    "                    'n_estimators': n_estimator,\n",
    "                    'max_depth': max_depth,\n",
    "                    'min_samples_split': min_samples_split\n",
    "                })\n",
    "\n",
    "                mlflow.log_metric(\"accuracy\", accuracy)\n",
    "                mlflow.log_metric('precision', precision)\n",
    "                mlflow.log_metric('recall', recall)\n",
    "\n",
    "                mlflow.log_artifact(X_train_file)\n",
    "                mlflow.log_artifact(X_test_file)\n",
    "                mlflow.log_artifact(y_train_file)\n",
    "                mlflow.log_artifact(y_test_file)\n",
    "\n",
    "        mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get feature importances\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Get the indices of features sorted by importance\n",
    "indices = np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  5,  3,  0,  1,  2,  6, 11, 10,  8, 12,  9,  7])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = indices[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_subset = X_train.iloc[:, top]\n",
    "X_test_subset = X_test.iloc[:, top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_subset_file = \"saved_data/X_train_subset.csv\"\n",
    "X_test_subset_file = \"saved_data/X_test_subset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train_subset).to_csv(X_train_subset_file, index=False)\n",
    "pd.DataFrame(X_test_subset).to_csv(X_test_subset_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Subsetted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "\n",
    "    mlflow.log_artifact(X_train_subset_file)\n",
    "    mlflow.log_artifact(X_test_subset_file)\n",
    "    mlflow.log_artifact(y_train_file)\n",
    "    mlflow.log_artifact(y_test_file)\n",
    "\n",
    "    mlflow.set_tags({\"Model\":\"Logistic Regression\", \"Train Data\": \"Subset Features\"})\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000, random_state=39)\n",
    "    model.fit(X_train_subset, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test_subset)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric('precision', precision)\n",
    "    mlflow.log_metric('recall', recall)\n",
    "mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Subsetted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for max_depth in max_depths:\n",
    "    for min_samples_split in min_samples_splits:\n",
    "        for min_samples_leaf in min_samples_leaves:\n",
    "            with mlflow.start_run():\n",
    "\n",
    "                mlflow.set_tags({\"Model\":\"Decision Tree\", \"Train Data\": \"Subset Features\"})\n",
    "\n",
    "                dt = DecisionTreeClassifier(max_depth=max_depth,\n",
    "                                            min_samples_split=min_samples_split,\n",
    "                                            min_samples_leaf=min_samples_leaf,\n",
    "                                            random_state=39)\n",
    "\n",
    "                dt.fit(X_train_subset, y_train)\n",
    "\n",
    "                y_pred = dt.predict(X_test_subset)\n",
    "\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision = precision_score(y_test, y_pred)\n",
    "                recall = recall_score(y_test, y_pred)\n",
    "\n",
    "                mlflow.log_params({\n",
    "                    'max_depth': max_depth,\n",
    "                    'min_samples_split': min_samples_split,\n",
    "                    'min_samples_leaf': min_samples_leaf\n",
    "                })\n",
    "\n",
    "                mlflow.log_metric(\"accuracy\", accuracy)\n",
    "                mlflow.log_metric('precision', precision)\n",
    "                mlflow.log_metric('recall', recall)\n",
    "\n",
    "                mlflow.log_artifact(X_train_subset_file)\n",
    "                mlflow.log_artifact(X_test_subset_file)\n",
    "                mlflow.log_artifact(y_train_file)\n",
    "                mlflow.log_artifact(y_test_file)\n",
    "\n",
    "        mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Subsetted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_estimator in n_estimators:\n",
    "    for max_depth in max_depths:\n",
    "        for min_samples_split in min_samples_splits:\n",
    "            with mlflow.start_run():\n",
    "\n",
    "                mlflow.set_tags({\"Model\":\"Random Forest\", \"Train Data\": \"Subset Features\"})\n",
    "\n",
    "                rf = RandomForestClassifier(n_estimators=n_estimator,\n",
    "                                            max_depth=max_depth,\n",
    "                                            min_samples_split=min_samples_split,\n",
    "                                            random_state=39)\n",
    "                rf.fit(X_train_subset, y_train)\n",
    "\n",
    "                y_pred = rf.predict(X_test_subset)\n",
    "\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision = precision_score(y_test, y_pred)\n",
    "                recall = recall_score(y_test, y_pred)\n",
    "\n",
    "                mlflow.log_params({\n",
    "                    'n_estimators': n_estimator,\n",
    "                    'max_depth': max_depth,\n",
    "                    'min_samples_split': min_samples_split\n",
    "                })\n",
    "\n",
    "                mlflow.log_metric(\"accuracy\", accuracy)\n",
    "                mlflow.log_metric('precision', precision)\n",
    "                mlflow.log_metric('recall', recall)\n",
    "\n",
    "                mlflow.log_artifact(X_train_subset_file)\n",
    "                mlflow.log_artifact(X_test_subset_file)\n",
    "                mlflow.log_artifact(y_train_file)\n",
    "                mlflow.log_artifact(y_test_file)\n",
    "\n",
    "        mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three best model run IDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* f283c99e6ad748448e9c39303253c00d\n",
    "* a303e9b961204ee59179bddcbbb893c0\n",
    "* d07256f6d2e749658aa5989099c4c432"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.96515, 0.842847075405215, 0.7161676646706587)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "best_model = DecisionTreeClassifier(max_depth=20,\n",
    "                            min_samples_split=4,\n",
    "                            min_samples_leaf=2,\n",
    "                            random_state=39)\n",
    "\n",
    "best_model.fit(X_train_subset, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_test_subset)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.sklearn.save_model(best_model, \"best_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'best_classification_model'.\n",
      "Created version '1' of model 'best_classification_model'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1725307767017, current_stage='None', description=None, last_updated_timestamp=1725307767017, name='best_classification_model', run_id=None, run_link=None, source='file://best_model', status='READY', status_message=None, tags={}, user_id=None, version=1>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.register_model(f\"file://best_model\", \"best_classification_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
